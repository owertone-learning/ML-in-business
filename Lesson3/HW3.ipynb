{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f975470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "636377e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>22113</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>93.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>22584</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>95.0</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>17668</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>71.0</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>19834</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>68.0</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "5   8  21914       1     151    67.0    120     80            2     2      0   \n",
       "6   9  22113       1     157    93.0    130     80            3     1      0   \n",
       "7  12  22584       2     178    95.0    130     90            3     3      0   \n",
       "8  13  17668       1     158    71.0    110     70            1     1      0   \n",
       "9  14  19834       1     164    68.0    110     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  \n",
       "5     0       0       0  \n",
       "6     0       1       0  \n",
       "7     0       1       1  \n",
       "8     0       1       0  \n",
       "9     0       0       0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_case2.csv', ';')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2f678dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('cardio', axis=1), \n",
    "                                                    df['cardio'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e1f7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "cat_cols = ['gender', 'cholesterol']\n",
    "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "continuos_transformers = []\n",
    "cat_transformers = []\n",
    "base_transformers = []\n",
    "\n",
    "for cont_col in continuos_cols:\n",
    "    transfomer =  Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    continuos_transformers.append((cont_col, transfomer))\n",
    "    \n",
    "for cat_col in cat_cols:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    cat_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for base_col in base_cols:\n",
    "    base_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=base_col))\n",
    "            ])\n",
    "    base_transformers.append((base_col, base_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6d0482b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73391771,  0.6873301 ,  0.74843904, ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.67343538,  0.07758923, -0.29640123, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.13738132,  1.17512278, -0.15708919, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.17775864,  1.17512278, -0.15708919, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.47190715, -1.38578883,  0.74843904, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.38174619,  0.56538192, -0.08743318, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "\n",
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a160522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем пустой датафрейм для хранения результатов\n",
    "results_df = pd.DataFrame(columns=['Classifier', 'Thresholds', 'Precision', 'Recall', 'F1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bff46917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.7867401104915408+-0.00852135511666111\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LogisticRegression(random_state = 42)),\n",
    "])\n",
    "\n",
    "\n",
    "#запустим кросс-валидацию\n",
    "cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
    "\n",
    "#обучим пайплайн на всем тренировочном датасете\n",
    "classifier.fit(X_train, y_train)\n",
    "y_score = classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bbd23f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.386937, F-Score=0.730, Precision=0.647, Recall=0.838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score\n",
    "b=1\n",
    "precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
    "fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))\n",
    "\n",
    "results_df = results_df.append({'Classifier': 'Logistic Regression', 'Thresholds': thresholds[ix],'Precision': precision[ix], 'Recall': recall[ix], 'F1-score': fscore[ix]}, \n",
    "                               ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "965fe474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.8025125910838183+-0.00707472977074522\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('features', feats),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42)), # Добавляем бустинг\n",
    "    # ('classifier', RandomForestClassifier(random_state=42)), # Добавляем случайный лес\n",
    "])\n",
    "\n",
    "# Запустим кросс-валидацию\n",
    "cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
    "\n",
    "# Обучим пайплайн на всем тренировочном датасете\n",
    "classifier.fit(X_train, y_train)\n",
    "y_score = classifier.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e4b0d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.394947, F-Score=0.740, Precision=0.698, Recall=0.788\n"
     ]
    }
   ],
   "source": [
    "b=1\n",
    "precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
    "fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))\n",
    "\n",
    "results_df = results_df.append({'Classifier': 'Gradient Boosting', 'Thresholds': thresholds[ix],'Precision': precision[ix], 'Recall': recall[ix], 'F1-score': fscore[ix]}, \n",
    "                               ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "12bf1388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.7734501681056019+-0.007171140345435727\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('features', feats),\n",
    "    #('classifier', GradientBoostingClassifier(random_state=42)), # Добавляем бустинг\n",
    "     ('classifier', RandomForestClassifier(random_state=42)), # Добавляем случайный лес\n",
    "])\n",
    "\n",
    "# Запустим кросс-валидацию\n",
    "cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n",
    "cv_score = np.mean(cv_scores)\n",
    "cv_score_std = np.std(cv_scores)\n",
    "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
    "\n",
    "# Обучим пайплайн на всем тренировочном датасете\n",
    "classifier.fit(X_train, y_train)\n",
    "y_score = classifier.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96857ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.350000, F-Score=0.719, Precision=0.643, Recall=0.816\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Thresholds</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.386937</td>\n",
       "      <td>0.647431</td>\n",
       "      <td>0.837558</td>\n",
       "      <td>0.730323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.394947</td>\n",
       "      <td>0.697848</td>\n",
       "      <td>0.788134</td>\n",
       "      <td>0.740248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.642669</td>\n",
       "      <td>0.815553</td>\n",
       "      <td>0.718863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Thresholds  Precision    Recall  F1-score\n",
       "0  Logistic Regression    0.386937   0.647431  0.837558  0.730323\n",
       "1    Gradient Boosting    0.394947   0.697848  0.788134  0.740248\n",
       "2        Random Forest    0.350000   0.642669  0.815553  0.718863"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=1\n",
    "precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
    "fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))\n",
    "\n",
    "results_df = results_df.append({'Classifier': 'Random Forest', 'Thresholds': thresholds[ix],'Precision': precision[ix], 'Recall': recall[ix], 'F1-score': fscore[ix]}, \n",
    "                               ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60940611",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69651209",
   "metadata": {},
   "source": [
    "Logistic Regression показывает самое высокое значение полноты (0.837558), значит она смогла правильно определить большинство положительных случаев. \n",
    "\n",
    "Gradient Boosting показывает самое высокое значение точности (0.697848), значит она смогла правильно определить большинство положительных и отрицательных случаев. И самое высокое значение F1-score. Gradient Boosting так же показывает самый высокий порог (threshold).\n",
    "\n",
    "RandomForest имеет самое низкое значение точности (0.642669) и F1-меры (0.718863), что говорит нам о том, что в данном случае модель отрабатывает хуже по сравнению с другими моделями.\n",
    "\n",
    "Исходя из этого, можно сделать вывод, что модель Gradient Boosting показывает наилучшие результаты среди этих моделей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c2453",
   "metadata": {},
   "source": [
    "### Какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60470b45",
   "metadata": {},
   "source": [
    "В случае сильного дисбаланса классов, когда объектов одного класса намного больше, чем другого, метрика precision_recall_curve больше подходит для оценки модели, потому что она учитывает истинно положительные и ложно положительные классификации в положительном классе относительно количества объектов этого класса. А это очень важно при сильном дисбалансе классов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
